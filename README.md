# Decision-Tree


TODO:
    Implement gini index using the method of intropy for the better results and accuracy


Implementation of decision tree in python
dataset used : bank_note dataset with five attributes.



link: https://www.openml.org/d/1462



links: https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/


Linkes for confusion matrix: http://chem-eng.utoronto.ca/~datamining/dmc/model_evaluation_c.htm

creating the binary decision tree is actually dividing the input space 

A greedy approach is used to divide the space called recursivebinary spliting.

split with best cost is selected.

Regression: The cost function that is minimized to choose split point is the sum squared error across all training samples that fall within the rectangle.

Dataset used : BankNote dataset.

Zero rule classification: This predicts the majority class irrespective of the classifier.

Gini index:  is the name of cost function to split the dataset.

